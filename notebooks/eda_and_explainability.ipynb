{
    "cells":  [
                  {
                      "cell_type":  "markdown",
                      "id":  "be3bfb04",
                      "metadata":  {

                                   },
                      "source":  [
                                     "# EDA \u0026 SHAP/LIME Explainability Analysis for AQI Prediction\n",
                                     "\n",
                                     "## Overview\n",
                                     "This notebook performs comprehensive Exploratory Data Analysis (EDA) and uses SHAP and LIME for model-agnostic feature importance explanations."
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  2,
                      "id":  "b50c46b2-88df-40b7-ada6-3bfb378a8e3f",
                      "metadata":  {

                                   },
                      "outputs":  [
                                      {
                                          "name":  "stdout",
                                          "output_type":  "stream",
                                          "text":  [
                                                       "Requirement already satisfied: seaborn in d:\\pycharm\\summer\\aqipredictorkarachi\\aqi-predictor-karachi\\venv\\lib\\site-packages (0.13.0)\n",
                                                       "Requirement already satisfied: matplotlib!=3.6.1,\u003e=3.3 in d:\\pycharm\\summer\\aqipredictorkarachi\\aqi-predictor-karachi\\venv\\lib\\site-packages (from seaborn) (3.8.2)\n",
                                                       "Requirement already satisfied: numpy!=1.24.0,\u003e=1.20 in d:\\pycharm\\summer\\aqipredictorkarachi\\aqi-predictor-karachi\\venv\\lib\\site-packages (from seaborn) (1.24.3)\n",
                                                       "Requirement already satisfied: pandas\u003e=1.2 in d:\\pycharm\\summer\\aqipredictorkarachi\\aqi-predictor-karachi\\venv\\lib\\site-packages (from seaborn) (2.1.4)\n",
                                                       "Requirement already satisfied: pyparsing\u003e=2.3.1 in d:\\pycharm\\summer\\aqipredictorkarachi\\aqi-predictor-karachi\\venv\\lib\\site-packages (from matplotlib!=3.6.1,\u003e=3.3-\u003eseaborn) (3.3.1)\n",
                                                       "Requirement already satisfied: kiwisolver\u003e=1.3.1 in d:\\pycharm\\summer\\aqipredictorkarachi\\aqi-predictor-karachi\\venv\\lib\\site-packages (from matplotlib!=3.6.1,\u003e=3.3-\u003eseaborn) (1.4.9)\n",
                                                       "Requirement already satisfied: cycler\u003e=0.10 in d:\\pycharm\\summer\\aqipredictorkarachi\\aqi-predictor-karachi\\venv\\lib\\site-packages (from matplotlib!=3.6.1,\u003e=3.3-\u003eseaborn) (0.12.1)\n",
                                                       "Requirement already satisfied: fonttools\u003e=4.22.0 in d:\\pycharm\\summer\\aqipredictorkarachi\\aqi-predictor-karachi\\venv\\lib\\site-packages (from matplotlib!=3.6.1,\u003e=3.3-\u003eseaborn) (4.61.1)\n",
                                                       "Requirement already satisfied: packaging\u003e=20.0 in d:\\pycharm\\summer\\aqipredictorkarachi\\aqi-predictor-karachi\\venv\\lib\\site-packages (from matplotlib!=3.6.1,\u003e=3.3-\u003eseaborn) (23.2)\n",
                                                       "Requirement already satisfied: python-dateutil\u003e=2.7 in d:\\pycharm\\summer\\aqipredictorkarachi\\aqi-predictor-karachi\\venv\\lib\\site-packages (from matplotlib!=3.6.1,\u003e=3.3-\u003eseaborn) (2.9.0.post0)\n",
                                                       "Requirement already satisfied: pillow\u003e=8 in d:\\pycharm\\summer\\aqipredictorkarachi\\aqi-predictor-karachi\\venv\\lib\\site-packages (from matplotlib!=3.6.1,\u003e=3.3-\u003eseaborn) (10.4.0)\n",
                                                       "Requirement already satisfied: contourpy\u003e=1.0.1 in d:\\pycharm\\summer\\aqipredictorkarachi\\aqi-predictor-karachi\\venv\\lib\\site-packages (from matplotlib!=3.6.1,\u003e=3.3-\u003eseaborn) (1.3.2)\n",
                                                       "Requirement already satisfied: pytz\u003e=2020.1 in d:\\pycharm\\summer\\aqipredictorkarachi\\aqi-predictor-karachi\\venv\\lib\\site-packages (from pandas\u003e=1.2-\u003eseaborn) (2025.2)\n",
                                                       "Requirement already satisfied: tzdata\u003e=2022.1 in d:\\pycharm\\summer\\aqipredictorkarachi\\aqi-predictor-karachi\\venv\\lib\\site-packages (from pandas\u003e=1.2-\u003eseaborn) (2025.3)\n",
                                                       "Requirement already satisfied: six\u003e=1.5 in d:\\pycharm\\summer\\aqipredictorkarachi\\aqi-predictor-karachi\\venv\\lib\\site-packages (from python-dateutil\u003e=2.7-\u003ematplotlib!=3.6.1,\u003e=3.3-\u003eseaborn) (1.17.0)\n"
                                                   ]
                                      }
                                  ],
                      "source":  [
                                     "!pip install seaborn"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  1,
                      "id":  "1293c896",
                      "metadata":  {

                                   },
                      "outputs":  [
                                      {
                                          "ename":  "ModuleNotFoundError",
                                          "evalue":  "No module named \u0027seaborn\u0027",
                                          "output_type":  "error",
                                          "traceback":  [
                                                            "\u001b[1;31m-----------\u001b[0m",
                                                            "\u001b[1;31mModuleNotFoundError\u001b[0mTraceback (most recent call last)",
                                                            "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----\u003e 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[0;32m      7\u001b[0m warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m\u0027\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\u0027\u001b[39m)\n",
                                                            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named \u0027seaborn\u0027"
                                                        ]
                                      }
                                  ],
                      "source":  [
                                     "# Import required libraries\n",
                                     "import pandas as pd\n",
                                     "import numpy as np\n",
                                     "import matplotlib.pyplot as plt\n",
                                     "import seaborn as sns\n",
                                     "import warnings\n",
                                     "warnings.filterwarnings(\u0027ignore\u0027)\n",
                                     "\n",
                                     "# Set style\n",
                                     "sns.set_style(\u0027darkgrid\u0027)\n",
                                     "plt.rcParams[\u0027figure.figsize\u0027] = (14, 8)\n",
                                     "\n",
                                     "import sys\n",
                                     "sys.path.insert(0, \u0027../\u0027)\n",
                                     "\n",
                                     "print(\"Libraries loaded successfully!\")"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "id":  "143bb82c",
                      "metadata":  {

                                   },
                      "source":  [
                                     "## Section 1: Load Data and Models"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "id":  "d8da63c5",
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "from src.mongodb_handler import MongoDBHandler\n",
                                     "from src.feature_engineering import FeatureEngineer\n",
                                     "import joblib\n",
                                     "import json\n",
                                     "\n",
                                     "# Load data from MongoDB\n",
                                     "print(\"Loading data from MongoDB...\")\n",
                                     "db_handler = MongoDBHandler()\n",
                                     "df = db_handler.get_training_data(days=60)\n",
                                     "db_handler.close()\n",
                                     "\n",
                                     "print(f\"[OK] Loaded {len(df)} records\")\n",
                                     "print(f\"\\nData shape: {df.shape}\")\n",
                                     "print(f\"\\nFirst few rows:\")\n",
                                     "print(df.head())"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "id":  "76c74a07",
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "# Load trained models\n",
                                     "print(\"Loading trained models...\")\n",
                                     "models = {}\n",
                                     "model_dir = \u0027../models/saved_models\u0027\n",
                                     "\n",
                                     "models[\u0027Ridge\u0027] = joblib.load(f\u0027{model_dir}/ridge_latest.pkl\u0027)\n",
                                     "models[\u0027Gradient Boosting\u0027] = joblib.load(f\u0027{model_dir}/gradient_boosting_latest.pkl\u0027)\n",
                                     "models[\u0027Random Forest\u0027] = joblib.load(f\u0027{model_dir}/random_forest_latest.pkl\u0027)\n",
                                     "\n",
                                     "print(\"[OK] All models loaded\")\n",
                                     "print(f\"\\nModels: {list(models.keys())}\")"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "id":  "6f39c32d",
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "# Load feature names\n",
                                     "with open(\u0027../models/saved_models/feature_names.json\u0027, \u0027r\u0027) as f:\n",
                                     "    feature_data = json.load(f)\n",
                                     "    if isinstance(feature_data, dict) and \u0027features\u0027 in feature_data:\n",
                                     "        feature_names = feature_data[\u0027features\u0027]\n",
                                     "    else:\n",
                                     "        feature_names = feature_data\n",
                                     "\n",
                                     "print(f\"Number of features: {len(feature_names)}\")\n",
                                     "print(f\"\\nFeatures: {feature_names[:10]}...\")"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "id":  "01e8a836",
                      "metadata":  {

                                   },
                      "source":  [
                                     "## Section 2: Exploratory Data Analysis (EDA)"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "id":  "f5b60993",
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "# Basic statistics\n",
                                     "print(\"Data Statistics:\")\n",
                                     "print(\"=\"*60)\n",
                                     "print(f\"\\nAQI - Target Variable:\")\n",
                                     "print(df[\u0027aqi\u0027].describe())\n",
                                     "\n",
                                     "print(f\"\\n\\nPollutant Concentrations:\")\n",
                                     "pollutants = [\u0027pm25\u0027, \u0027pm10\u0027, \u0027no2\u0027, \u0027so2\u0027, \u0027co\u0027, \u0027o3\u0027]\n",
                                     "print(df[pollutants].describe())"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "id":  "9cb04da5",
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "# AQI Distribution\n",
                                     "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
                                     "\n",
                                     "# Histogram\n",
                                     "axes[0, 0].hist(df[\u0027aqi\u0027], bins=30, color=\u0027steelblue\u0027, edgecolor=\u0027black\u0027, alpha=0.7)\n",
                                     "axes[0, 0].set_title(\u0027AQI Distribution\u0027, fontsize=12, fontweight=\u0027bold\u0027)\n",
                                     "axes[0, 0].set_xlabel(\u0027AQI Value\u0027)\n",
                                     "axes[0, 0].set_ylabel(\u0027Frequency\u0027)\n",
                                     "\n",
                                     "# Box plot\n",
                                     "axes[0, 1].boxplot(df[\u0027aqi\u0027], vert=True)\n",
                                     "axes[0, 1].set_title(\u0027AQI Box Plot\u0027, fontsize=12, fontweight=\u0027bold\u0027)\n",
                                     "axes[0, 1].set_ylabel(\u0027AQI Value\u0027)\n",
                                     "\n",
                                     "# Time series\n",
                                     "if \u0027timestamp\u0027 in df.columns:\n",
                                     "    df_sorted = df.sort_values(\u0027timestamp\u0027)\n",
                                     "    axes[1, 0].plot(df_sorted[\u0027timestamp\u0027], df_sorted[\u0027aqi\u0027], color=\u0027steelblue\u0027, alpha=0.7)\n",
                                     "    axes[1, 0].set_title(\u0027AQI Time Series\u0027, fontsize=12, fontweight=\u0027bold\u0027)\n",
                                     "    axes[1, 0].set_xlabel(\u0027Date\u0027)\n",
                                     "    axes[1, 0].set_ylabel(\u0027AQI Value\u0027)\n",
                                     "    axes[1, 0].tick_params(axis=\u0027x\u0027, rotation=45)\n",
                                     "\n",
                                     "# Pollutants correlation with AQI\n",
                                     "pollutants_with_aqi = pollutants + [\u0027aqi\u0027]\n",
                                     "corr_with_aqi = df[pollutants_with_aqi].corr()[\u0027aqi\u0027].drop(\u0027aqi\u0027).sort_values(ascending=False)\n",
                                     "axes[1, 1].barh(corr_with_aqi.index, corr_with_aqi.values, color=\u0027coral\u0027)\n",
                                     "axes[1, 1].set_title(\u0027Pollutant Correlation with AQI\u0027, fontsize=12, fontweight=\u0027bold\u0027)\n",
                                     "axes[1, 1].set_xlabel(\u0027Correlation Coefficient\u0027)\n",
                                     "\n",
                                     "plt.tight_layout()\n",
                                     "plt.savefig(\u0027../notebooks/plots/eda_overview.png\u0027, dpi=300, bbox_inches=\u0027tight\u0027)\n",
                                     "plt.show()\n",
                                     "\n",
                                     "print(f\"\\nPollutant Correlations with AQI:\")\n",
                                     "print(corr_with_aqi)"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "id":  "e7615f25",
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "# Correlation matrix heatmap\n",
                                     "fig, ax = plt.subplots(figsize=(12, 10))\n",
                                     "corr_matrix = df[pollutants_with_aqi].corr()\n",
                                     "sns.heatmap(corr_matrix, annot=True, fmt=\u0027.2f\u0027, cmap=\u0027coolwarm\u0027, center=0, ax=ax, cbar_kws={\u0027label\u0027: \u0027Correlation\u0027})\n",
                                     "ax.set_title(\u0027Correlation Matrix: Pollutants and AQI\u0027, fontsize=14, fontweight=\u0027bold\u0027)\n",
                                     "plt.tight_layout()\n",
                                     "plt.savefig(\u0027../notebooks/plots/correlation_heatmap.png\u0027, dpi=300, bbox_inches=\u0027tight\u0027)\n",
                                     "plt.show()"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "id":  "1de22017",
                      "metadata":  {

                                   },
                      "source":  [
                                     "## Section 3: Prepare Features and Generate Predictions"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "id":  "65eb6023",
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "# Prepare features using the same approach as model training",
                                     "print(\"Preparing features...\")",
                                     "",
                                     "# Use the same column exclusion as ModelTrainer",
                                     "exclude_cols = [\u0027aqi\u0027, \u0027timestamp\u0027, \u0027date\u0027, \u0027_id\u0027, \u0027inserted_at\u0027, ",
                                     "                \u0027station_name\u0027, \u0027latitude\u0027, \u0027longitude\u0027]",
                                     "",
                                     "# Use features that the model was trained on (from feature_names.json)",
                                     "# Only use columns that exist in both feature_names and df",
                                     "available_features = [f for f in feature_names if f in df.columns]",
                                     "",
                                     "if not available_features:",
                                     "    print(f\"[WARN] No matching features. Falling back to numeric columns...\")",
                                     "    available_features = [col for col in df.columns ",
                                     "                         if col not in exclude_cols ",
                                     "                         and df[col].dtype in [\u0027int64\u0027, \u0027float64\u0027]]",
                                     "",
                                     "print(f\"Using {len(available_features)} features: {available_features[:5]}...\")",
                                     "",
                                     "# Create feature matrix directly from DataFrame columns",
                                     "X = df[available_features].copy()",
                                     "X = X.fillna(X.median(numeric_only=True))",
                                     "y = df[\u0027aqi\u0027].values",
                                     "",
                                     "print(f\"[OK] Feature matrix shape: {X.shape}\")",
                                     "print(f\"[OK] Target shape: {y.shape}\")",
                                     "",
                                     "# Update feature_names to match what we\u0027re using",
                                     "feature_names = available_features"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "id":  "61358eb8",
                      "metadata":  {

                                   },
                      "source":  [
                                     "## Section 4: SHAP Feature Importance Analysis"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "id":  "d6c2ab11",
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "import shap\n",
                                     "\n",
                                     "print(\"Generating SHAP Explanations...\\n\")\n",
                                     "\n",
                                     "# For each model\n",
                                     "shap_results = {}\n",
                                     "\n",
                                     "for model_name, model in models.items():\n",
                                     "    print(f\"Processing {model_name}...\")\n",
                                     "    \n",
                                     "    try:\n",
                                     "        # Sample data for SHAP\n",
                                     "        background_data = X.iloc[:min(100, len(X))]\n",
                                     "        \n",
                                     "        # Create SHAP explainer\n",
                                     "        if \u0027RandomForest\u0027 in str(type(model).__name__) or \u0027GradientBoosting\u0027 in str(type(model).__name__):\n",
                                     "            explainer = shap.TreeExplainer(model)\n",
                                     "        else:\n",
                                     "            explainer = shap.KernelExplainer(model.predict, background_data)\n",
                                     "        \n",
                                     "        # Calculate SHAP values\n",
                                     "        shap_values = explainer.shap_values(X.iloc[:min(100, len(X))])\n",
                                     "        \n",
                                     "        # Handle different formats\n",
                                     "        if isinstance(shap_values, list):\n",
                                     "            shap_values = shap_values[0]\n",
                                     "        \n",
                                     "        # Calculate feature importance\n",
                                     "        feature_importance = np.abs(shap_values).mean(axis=0)\n",
                                     "        importance_df = pd.DataFrame({\n",
                                     "            \u0027Feature\u0027: X.columns,\n",
                                     "            \u0027Importance\u0027: feature_importance\n",
                                     "        }).sort_values(\u0027Importance\u0027, ascending=False)\n",
                                     "        \n",
                                     "        shap_results[model_name] = importance_df\n",
                                     "        \n",
                                     "        print(f\"[OK] {model_name} - Top 10 Features:\")\n",
                                     "        for idx, row in importance_df.head(10).iterrows():\n",
                                     "            print(f\"    {row[\u0027Feature\u0027]:.\u003c40} {row[\u0027Importance\u0027]:.4f}\")\n",
                                     "        print()\n",
                                     "        \n",
                                     "    except Exception as e:\n",
                                     "        print(f\"[FAIL] Error with {model_name}: {e}\\n\")"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "id":  "f4daef03",
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "# Visualize SHAP importance for all models\n",
                                     "fig, axes = plt.subplots(1, 3, figsize=(20, 8))\n",
                                     "\n",
                                     "for idx, (model_name, importance_df) in enumerate(shap_results.items()):\n",
                                     "    top_features = importance_df.head(15)\n",
                                     "    axes[idx].barh(top_features[\u0027Feature\u0027], top_features[\u0027Importance\u0027], color=f\u0027C{idx}\u0027)\n",
                                     "    axes[idx].set_xlabel(\u0027Mean |SHAP value|\u0027)\n",
                                     "    axes[idx].set_title(f\u0027SHAP Feature Importance - {model_name}\u0027, fontweight=\u0027bold\u0027)\n",
                                     "    axes[idx].invert_yaxis()\n",
                                     "\n",
                                     "plt.suptitle(\u0027SHAP Feature Importance Across All Models\u0027, fontsize=16, fontweight=\u0027bold\u0027)\n",
                                     "plt.tight_layout()\n",
                                     "plt.savefig(\u0027../notebooks/plots/shap_importance_all_models.png\u0027, dpi=300, bbox_inches=\u0027tight\u0027)\n",
                                     "plt.show()\n",
                                     "\n",
                                     "print(\"SHAP importance plots saved!\")"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "id":  "8ebf54ec",
                      "metadata":  {

                                   },
                      "source":  [
                                     "## Section 5: LIME Feature Importance Analysis"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "id":  "aaa38e93",
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "import lime\n",
                                     "import lime.lime_tabular\n",
                                     "\n",
                                     "print(\"Generating LIME Explanations...\\n\")\n",
                                     "\n",
                                     "lime_results = {}\n",
                                     "\n",
                                     "for model_name, model in models.items():\n",
                                     "    print(f\"Processing {model_name}...\")\n",
                                     "    \n",
                                     "    try:\n",
                                     "        # Create LIME explainer\n",
                                     "        explainer = lime.lime_tabular.LimeTabularExplainer(\n",
                                     "            X.values,\n",
                                     "            feature_names=X.columns.tolist(),\n",
                                     "            mode=\u0027regression\u0027,\n",
                                     "            verbose=False\n",
                                     "        )\n",
                                     "        \n",
                                     "        # Explain multiple instances\n",
                                     "        lime_importances = pd.DataFrame(columns=[\u0027Feature\u0027, \u0027Weight\u0027])\n",
                                     "        \n",
                                     "        for i in range(min(5, len(X))):\n",
                                     "            exp = explainer.explain_instance(X.iloc[i], model.predict, num_features=20)\n",
                                     "            exp_list = exp.as_list()\n",
                                     "            \n",
                                     "            for feature, weight in exp_list:\n",
                                     "                feature_name = feature.split()[0] if feature else \u0027unknown\u0027\n",
                                     "                if feature_name in X.columns:\n",
                                     "                    lime_importances = pd.concat([\n",
                                     "                        lime_importances,\n",
                                     "                        pd.DataFrame({\u0027Feature\u0027: [feature_name], \u0027Weight\u0027: [abs(weight)]})\n",
                                     "                    ], ignore_index=True)\n",
                                     "        \n",
                                     "        # Aggregate\n",
                                     "        if len(lime_importances) \u003e 0:\n",
                                     "            lime_agg = lime_importances.groupby(\u0027Feature\u0027)[\u0027Weight\u0027].mean().sort_values(ascending=False)\n",
                                     "            lime_results[model_name] = lime_agg\n",
                                     "            \n",
                                     "            print(f\"[OK] {model_name} - Top 10 Features:\")\n",
                                     "            for idx, (feature, weight) in enumerate(lime_agg.head(10).items()):\n",
                                     "                print(f\"    {feature:.\u003c40} {weight:.4f}\")\n",
                                     "            print()\n",
                                     "        else:\n",
                                     "            print(f\"[FAIL] No LIME importances for {model_name}\\n\")\n",
                                     "            \n",
                                     "    except Exception as e:\n",
                                     "        print(f\"[FAIL] Error with {model_name}: {e}\\n\")"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "id":  "03bc6476",
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "# Visualize LIME importance\n",
                                     "fig, axes = plt.subplots(1, 3, figsize=(20, 8))\n",
                                     "\n",
                                     "for idx, (model_name, importance_series) in enumerate(lime_results.items()):\n",
                                     "    top_features = importance_series.head(15)\n",
                                     "    axes[idx].barh(top_features.index, top_features.values, color=f\u0027C{idx+3}\u0027)\n",
                                     "    axes[idx].set_xlabel(\u0027Mean Weight\u0027)\n",
                                     "    axes[idx].set_title(f\u0027LIME Feature Importance - {model_name}\u0027, fontweight=\u0027bold\u0027)\n",
                                     "    axes[idx].invert_yaxis()\n",
                                     "\n",
                                     "plt.suptitle(\u0027LIME Feature Importance Across All Models\u0027, fontsize=16, fontweight=\u0027bold\u0027)\n",
                                     "plt.tight_layout()\n",
                                     "plt.savefig(\u0027../notebooks/plots/lime_importance_all_models.png\u0027, dpi=300, bbox_inches=\u0027tight\u0027)\n",
                                     "plt.show()\n",
                                     "\n",
                                     "print(\"LIME importance plots saved!\")"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "id":  "143001ef",
                      "metadata":  {

                                   },
                      "source":  [
                                     "## Section 6: Key Findings Summary"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "id":  "6392e9bf",
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "print(\"\\n\" + \"=\"*80)\n",
                                     "print(\"KEY FINDINGS - FEATURE IMPORTANCE SUMMARY\")\n",
                                     "print(\"=\"*80)\n",
                                     "\n",
                                     "print(\"\\n1. SHAP ANALYSIS (SHAPLEY VALUES):\")\n",
                                     "print(\"-\" * 80)\n",
                                     "for model_name, importance_df in shap_results.items():\n",
                                     "    print(f\"\\n{model_name}:\")\n",
                                     "    print(f\"  Top 5 Features:\")\n",
                                     "    for idx, row in importance_df.head(5).iterrows():\n",
                                     "        print(f\"    â€¢ {row[\u0027Feature\u0027]:.\u003c40} {row[\u0027Importance\u0027]:.4f}\")\n",
                                     "\n",
                                     "print(\"\\n\\n2. LIME ANALYSIS (LOCAL INTERPRETABLE MODEL-AGNOSTIC):\")\n",
                                     "print(\"-\" * 80)\n",
                                     "for model_name, importance_series in lime_results.items():\n",
                                     "    print(f\"\\n{model_name}:\")\n",
                                     "    print(f\"  Top 5 Features:\")\n",
                                     "    for idx, (feature, weight) in enumerate(importance_series.head(5).items()):\n",
                                     "        print(f\"    â€¢ {feature:.\u003c40} {weight:.4f}\")\n",
                                     "\n",
                                     "print(\"\\n\\n3. TREND ANALYSIS:\")\n",
                                     "print(\"-\" * 80)\n",
                                     "print(f\"  Data Points: {len(df)}\")\n",
                                     "print(f\"  AQI Range: {df[\u0027aqi\u0027].min():.1f} - {df[\u0027aqi\u0027].max():.1f}\")\n",
                                     "print(f\"  AQI Mean: {df[\u0027aqi\u0027].mean():.1f}\")\n",
                                     "print(f\"  AQI Std Dev: {df[\u0027aqi\u0027].std():.1f}\")\n",
                                     "\n",
                                     "print(\"\\n  Top Pollutant Correlations with AQI:\")\n",
                                     "corr_with_aqi_sorted = df[pollutants_with_aqi].corr()[\u0027aqi\u0027].drop(\u0027aqi\u0027).sort_values(ascending=False)\n",
                                     "for feature, corr in corr_with_aqi_sorted.head(5).items():\n",
                                     "    print(f\"    â€¢ {feature:.\u003c40} {corr:.4f}\")\n",
                                     "\n",
                                     "print(\"\\n\" + \"=\"*80)\n",
                                     "print(\"Analysis Complete!\")\n",
                                     "print(\"=\"*80)"
                                 ]
                  }
              ],
    "metadata":  {
                     "kernelspec":  {
                                        "display_name":  "Python 3 (ipykernel)",
                                        "language":  "python",
                                        "name":  "python3"
                                    },
                     "language_info":  {
                                           "codemirror_mode":  {
                                                                   "name":  "ipython",
                                                                   "version":  3
                                                               },
                                           "file_extension":  ".py",
                                           "mimetype":  "text/x-python",
                                           "name":  "python",
                                           "nbconvert_exporter":  "python",
                                           "pygments_lexer":  "ipython3",
                                           "version":  "3.10.0"
                                       }
                 },
    "nbformat":  4,
    "nbformat_minor":  5
}
