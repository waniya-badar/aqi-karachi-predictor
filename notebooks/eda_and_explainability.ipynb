{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "be3bfb04",
            "metadata": {},
            "source": [
                "# EDA & SHAP/LIME Explainability Analysis for AQI Prediction\n",
                "\n",
                "## Overview\n",
                "This notebook performs comprehensive Exploratory Data Analysis (EDA) and uses SHAP and LIME for model-agnostic feature importance explanations."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "b50c46b2-88df-40b7-ada6-3bfb378a8e3f",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Requirement already satisfied: seaborn in d:\\pycharm\\summer\\aqipredictorkarachi\\aqi-predictor-karachi\\venv\\lib\\site-packages (0.13.0)\n",
                        "Requirement already satisfied: matplotlib!=3.6.1,>=3.3 in d:\\pycharm\\summer\\aqipredictorkarachi\\aqi-predictor-karachi\\venv\\lib\\site-packages (from seaborn) (3.8.2)\n",
                        "Requirement already satisfied: numpy!=1.24.0,>=1.20 in d:\\pycharm\\summer\\aqipredictorkarachi\\aqi-predictor-karachi\\venv\\lib\\site-packages (from seaborn) (1.24.3)\n",
                        "Requirement already satisfied: pandas>=1.2 in d:\\pycharm\\summer\\aqipredictorkarachi\\aqi-predictor-karachi\\venv\\lib\\site-packages (from seaborn) (2.1.4)\n",
                        "Requirement already satisfied: pyparsing>=2.3.1 in d:\\pycharm\\summer\\aqipredictorkarachi\\aqi-predictor-karachi\\venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (3.3.1)\n",
                        "Requirement already satisfied: kiwisolver>=1.3.1 in d:\\pycharm\\summer\\aqipredictorkarachi\\aqi-predictor-karachi\\venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (1.4.9)\n",
                        "Requirement already satisfied: cycler>=0.10 in d:\\pycharm\\summer\\aqipredictorkarachi\\aqi-predictor-karachi\\venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (0.12.1)\n",
                        "Requirement already satisfied: fonttools>=4.22.0 in d:\\pycharm\\summer\\aqipredictorkarachi\\aqi-predictor-karachi\\venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (4.61.1)\n",
                        "Requirement already satisfied: packaging>=20.0 in d:\\pycharm\\summer\\aqipredictorkarachi\\aqi-predictor-karachi\\venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (23.2)\n",
                        "Requirement already satisfied: python-dateutil>=2.7 in d:\\pycharm\\summer\\aqipredictorkarachi\\aqi-predictor-karachi\\venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (2.9.0.post0)\n",
                        "Requirement already satisfied: pillow>=8 in d:\\pycharm\\summer\\aqipredictorkarachi\\aqi-predictor-karachi\\venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (10.4.0)\n",
                        "Requirement already satisfied: contourpy>=1.0.1 in d:\\pycharm\\summer\\aqipredictorkarachi\\aqi-predictor-karachi\\venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (1.3.2)\n",
                        "Requirement already satisfied: pytz>=2020.1 in d:\\pycharm\\summer\\aqipredictorkarachi\\aqi-predictor-karachi\\venv\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
                        "Requirement already satisfied: tzdata>=2022.1 in d:\\pycharm\\summer\\aqipredictorkarachi\\aqi-predictor-karachi\\venv\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.3)\n",
                        "Requirement already satisfied: six>=1.5 in d:\\pycharm\\summer\\aqipredictorkarachi\\aqi-predictor-karachi\\venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.3->seaborn) (1.17.0)\n"
                    ]
                }
            ],
            "source": [
                "!pip install seaborn"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "1293c896",
            "metadata": {},
            "outputs": [
                {
                    "ename": "ModuleNotFoundError",
                    "evalue": "No module named 'seaborn'",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[1;31m-----------\u001b[0m",
                        "\u001b[1;31mModuleNotFoundError\u001b[0mTraceback (most recent call last)",
                        "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[0;32m      7\u001b[0m warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
                        "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
                    ]
                }
            ],
            "source": [
                "# Import required libraries\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "# Set style\n",
                "sns.set_style('darkgrid')\n",
                "plt.rcParams['figure.figsize'] = (14, 8)\n",
                "\n",
                "import sys\n",
                "sys.path.insert(0, '../')\n",
                "\n",
                "print(\"Libraries loaded successfully!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "143bb82c",
            "metadata": {},
            "source": [
                "## Section 1: Load Data and Models"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d8da63c5",
            "metadata": {},
            "outputs": [],
            "source": [
                "from src.mongodb_handler import MongoDBHandler\n",
                "from src.feature_engineering import FeatureEngineer\n",
                "import joblib\n",
                "import json\n",
                "\n",
                "# Load data from MongoDB\n",
                "print(\"Loading data from MongoDB...\")\n",
                "db_handler = MongoDBHandler()\n",
                "df = db_handler.get_training_data(days=60)\n",
                "db_handler.close()\n",
                "\n",
                "print(f\"[OK] Loaded {len(df)} records\")\n",
                "print(f\"\\nData shape: {df.shape}\")\n",
                "print(f\"\\nFirst few rows:\")\n",
                "print(df.head())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "76c74a07",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load trained models\n",
                "print(\"Loading trained models...\")\n",
                "models = {}\n",
                "model_dir = '../models/saved_models'\n",
                "\n",
                "models['Ridge'] = joblib.load(f'{model_dir}/ridge_latest.pkl')\n",
                "models['Gradient Boosting'] = joblib.load(f'{model_dir}/gradient_boosting_latest.pkl')\n",
                "models['Random Forest'] = joblib.load(f'{model_dir}/random_forest_latest.pkl')\n",
                "\n",
                "print(\"[OK] All models loaded\")\n",
                "print(f\"\\nModels: {list(models.keys())}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "6f39c32d",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load feature names\n",
                "with open('../models/saved_models/feature_names.json', 'r') as f:\n",
                "    feature_data = json.load(f)\n",
                "    if isinstance(feature_data, dict) and 'features' in feature_data:\n",
                "        feature_names = feature_data['features']\n",
                "    else:\n",
                "        feature_names = feature_data\n",
                "\n",
                "print(f\"Number of features: {len(feature_names)}\")\n",
                "print(f\"\\nFeatures: {feature_names[:10]}...\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "01e8a836",
            "metadata": {},
            "source": [
                "## Section 2: Exploratory Data Analysis (EDA)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f5b60993",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Basic statistics\n",
                "print(\"Data Statistics:\")\n",
                "print(\"=\"*60)\n",
                "print(f\"\\nAQI - Target Variable:\")\n",
                "print(df['aqi'].describe())\n",
                "\n",
                "print(f\"\\n\\nPollutant Concentrations:\")\n",
                "pollutants = ['pm25', 'pm10', 'no2', 'so2', 'co', 'o3']\n",
                "print(df[pollutants].describe())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "9cb04da5",
            "metadata": {},
            "outputs": [],
            "source": [
                "# AQI Distribution\n",
                "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
                "\n",
                "# Histogram\n",
                "axes[0, 0].hist(df['aqi'], bins=30, color='steelblue', edgecolor='black', alpha=0.7)\n",
                "axes[0, 0].set_title('AQI Distribution', fontsize=12, fontweight='bold')\n",
                "axes[0, 0].set_xlabel('AQI Value')\n",
                "axes[0, 0].set_ylabel('Frequency')\n",
                "\n",
                "# Box plot\n",
                "axes[0, 1].boxplot(df['aqi'], vert=True)\n",
                "axes[0, 1].set_title('AQI Box Plot', fontsize=12, fontweight='bold')\n",
                "axes[0, 1].set_ylabel('AQI Value')\n",
                "\n",
                "# Time series\n",
                "if 'timestamp' in df.columns:\n",
                "    df_sorted = df.sort_values('timestamp')\n",
                "    axes[1, 0].plot(df_sorted['timestamp'], df_sorted['aqi'], color='steelblue', alpha=0.7)\n",
                "    axes[1, 0].set_title('AQI Time Series', fontsize=12, fontweight='bold')\n",
                "    axes[1, 0].set_xlabel('Date')\n",
                "    axes[1, 0].set_ylabel('AQI Value')\n",
                "    axes[1, 0].tick_params(axis='x', rotation=45)\n",
                "\n",
                "# Pollutants correlation with AQI\n",
                "pollutants_with_aqi = pollutants + ['aqi']\n",
                "corr_with_aqi = df[pollutants_with_aqi].corr()['aqi'].drop('aqi').sort_values(ascending=False)\n",
                "axes[1, 1].barh(corr_with_aqi.index, corr_with_aqi.values, color='coral')\n",
                "axes[1, 1].set_title('Pollutant Correlation with AQI', fontsize=12, fontweight='bold')\n",
                "axes[1, 1].set_xlabel('Correlation Coefficient')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('../notebooks/plots/eda_overview.png', dpi=300, bbox_inches='tight')\n",
                "plt.show()\n",
                "\n",
                "print(f\"\\nPollutant Correlations with AQI:\")\n",
                "print(corr_with_aqi)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e7615f25",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Correlation matrix heatmap\n",
                "fig, ax = plt.subplots(figsize=(12, 10))\n",
                "corr_matrix = df[pollutants_with_aqi].corr()\n",
                "sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm', center=0, ax=ax, cbar_kws={'label': 'Correlation'})\n",
                "ax.set_title('Correlation Matrix: Pollutants and AQI', fontsize=14, fontweight='bold')\n",
                "plt.tight_layout()\n",
                "plt.savefig('../notebooks/plots/correlation_heatmap.png', dpi=300, bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "1de22017",
            "metadata": {},
            "source": [
                "## Section 3: Prepare Features and Generate Predictions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "65eb6023",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Prepare features using the same approach as model training\n",
                "print(\"Preparing features...\")\n",
                "\n",
                "# Use the same column exclusion as ModelTrainer\n",
                "exclude_cols = ['aqi', 'timestamp', 'date', '_id', 'inserted_at', \n",
                "                'station_name', 'latitude', 'longitude']\n",
                "\n",
                "# Use features that the model was trained on (from feature_names.json)\n",
                "# Only use columns that exist in both feature_names and df\n",
                "available_features = [f for f in feature_names if f in df.columns]\n",
                "\n",
                "if not available_features:\n",
                "    print(f\"[WARN] No matching features. Falling back to numeric columns...\")\n",
                "    available_features = [col for col in df.columns \n",
                "                         if col not in exclude_cols \n",
                "                         and df[col].dtype in ['int64', 'float64']]\n",
                "\n",
                "print(f\"Using {len(available_features)} features: {available_features[:5]}...\")\n",
                "\n",
                "# Create feature matrix directly from DataFrame columns\n",
                "X = df[available_features].copy()\n",
                "X = X.fillna(X.median(numeric_only=True))\n",
                "y = df['aqi'].values\n",
                "\n",
                "print(f\"[OK] Feature matrix shape: {X.shape}\")\n",
                "print(f\"[OK] Target shape: {y.shape}\")\n",
                "\n",
                "# Update feature_names to match what we're using\n",
                "feature_names = available_features"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "61358eb8",
            "metadata": {},
            "source": [
                "## Section 4: SHAP Feature Importance Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d6c2ab11",
            "metadata": {},
            "outputs": [],
            "source": [
                "import shap\n",
                "\n",
                "print(\"Generating SHAP Explanations...\\n\")\n",
                "\n",
                "# For each model\n",
                "shap_results = {}\n",
                "\n",
                "for model_name, model in models.items():\n",
                "    print(f\"Processing {model_name}...\")\n",
                "    \n",
                "    try:\n",
                "        # Sample data for SHAP\n",
                "        background_data = X.iloc[:min(100, len(X))]\n",
                "        \n",
                "        # Create SHAP explainer\n",
                "        if 'RandomForest' in str(type(model).__name__) or 'GradientBoosting' in str(type(model).__name__):\n",
                "            explainer = shap.TreeExplainer(model)\n",
                "        else:\n",
                "            explainer = shap.KernelExplainer(model.predict, background_data)\n",
                "        \n",
                "        # Calculate SHAP values\n",
                "        shap_values = explainer.shap_values(X.iloc[:min(100, len(X))])\n",
                "        \n",
                "        # Handle different formats\n",
                "        if isinstance(shap_values, list):\n",
                "            shap_values = shap_values[0]\n",
                "        \n",
                "        # Calculate feature importance\n",
                "        feature_importance = np.abs(shap_values).mean(axis=0)\n",
                "        importance_df = pd.DataFrame({\n",
                "            'Feature': X.columns,\n",
                "            'Importance': feature_importance\n",
                "        }).sort_values('Importance', ascending=False)\n",
                "        \n",
                "        shap_results[model_name] = importance_df\n",
                "        \n",
                "        print(f\"[OK] {model_name} - Top 10 Features:\")\n",
                "        for idx, row in importance_df.head(10).iterrows():\n",
                "            print(f\"    {row['Feature']:.<40} {row['Importance']:.4f}\")\n",
                "        print()\n",
                "        \n",
                "    except Exception as e:\n",
                "        print(f\"[FAIL] Error with {model_name}: {e}\\n\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f4daef03",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize SHAP importance for all models\n",
                "fig, axes = plt.subplots(1, 3, figsize=(20, 8))\n",
                "\n",
                "for idx, (model_name, importance_df) in enumerate(shap_results.items()):\n",
                "    top_features = importance_df.head(15)\n",
                "    axes[idx].barh(top_features['Feature'], top_features['Importance'], color=f'C{idx}')\n",
                "    axes[idx].set_xlabel('Mean |SHAP value|')\n",
                "    axes[idx].set_title(f'SHAP Feature Importance - {model_name}', fontweight='bold')\n",
                "    axes[idx].invert_yaxis()\n",
                "\n",
                "plt.suptitle('SHAP Feature Importance Across All Models', fontsize=16, fontweight='bold')\n",
                "plt.tight_layout()\n",
                "plt.savefig('../notebooks/plots/shap_importance_all_models.png', dpi=300, bbox_inches='tight')\n",
                "plt.show()\n",
                "\n",
                "print(\"SHAP importance plots saved!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "8ebf54ec",
            "metadata": {},
            "source": [
                "## Section 5: LIME Feature Importance Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "aaa38e93",
            "metadata": {},
            "outputs": [],
            "source": [
                "import lime\n",
                "import lime.lime_tabular\n",
                "\n",
                "print(\"Generating LIME Explanations...\\n\")\n",
                "\n",
                "lime_results = {}\n",
                "\n",
                "for model_name, model in models.items():\n",
                "    print(f\"Processing {model_name}...\")\n",
                "    \n",
                "    try:\n",
                "        # Create LIME explainer\n",
                "        explainer = lime.lime_tabular.LimeTabularExplainer(\n",
                "            X.values,\n",
                "            feature_names=X.columns.tolist(),\n",
                "            mode='regression',\n",
                "            verbose=False\n",
                "        )\n",
                "        \n",
                "        # Explain multiple instances\n",
                "        lime_importances = pd.DataFrame(columns=['Feature', 'Weight'])\n",
                "        \n",
                "        for i in range(min(5, len(X))):\n",
                "            exp = explainer.explain_instance(X.iloc[i], model.predict, num_features=20)\n",
                "            exp_list = exp.as_list()\n",
                "            \n",
                "            for feature, weight in exp_list:\n",
                "                feature_name = feature.split()[0] if feature else 'unknown'\n",
                "                if feature_name in X.columns:\n",
                "                    lime_importances = pd.concat([\n",
                "                        lime_importances,\n",
                "                        pd.DataFrame({'Feature': [feature_name], 'Weight': [abs(weight)]})\n",
                "                    ], ignore_index=True)\n",
                "        \n",
                "        # Aggregate\n",
                "        if len(lime_importances) > 0:\n",
                "            lime_agg = lime_importances.groupby('Feature')['Weight'].mean().sort_values(ascending=False)\n",
                "            lime_results[model_name] = lime_agg\n",
                "            \n",
                "            print(f\"[OK] {model_name} - Top 10 Features:\")\n",
                "            for idx, (feature, weight) in enumerate(lime_agg.head(10).items()):\n",
                "                print(f\"    {feature:.<40} {weight:.4f}\")\n",
                "            print()\n",
                "        else:\n",
                "            print(f\"[FAIL] No LIME importances for {model_name}\\n\")\n",
                "            \n",
                "    except Exception as e:\n",
                "        print(f\"[FAIL] Error with {model_name}: {e}\\n\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "03bc6476",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize LIME importance\n",
                "fig, axes = plt.subplots(1, 3, figsize=(20, 8))\n",
                "\n",
                "for idx, (model_name, importance_series) in enumerate(lime_results.items()):\n",
                "    top_features = importance_series.head(15)\n",
                "    axes[idx].barh(top_features.index, top_features.values, color=f'C{idx+3}')\n",
                "    axes[idx].set_xlabel('Mean Weight')\n",
                "    axes[idx].set_title(f'LIME Feature Importance - {model_name}', fontweight='bold')\n",
                "    axes[idx].invert_yaxis()\n",
                "\n",
                "plt.suptitle('LIME Feature Importance Across All Models', fontsize=16, fontweight='bold')\n",
                "plt.tight_layout()\n",
                "plt.savefig('../notebooks/plots/lime_importance_all_models.png', dpi=300, bbox_inches='tight')\n",
                "plt.show()\n",
                "\n",
                "print(\"LIME importance plots saved!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "143001ef",
            "metadata": {},
            "source": [
                "## Section 6: Key Findings Summary"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "6392e9bf",
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\n\" + \"=\"*80)\n",
                "print(\"KEY FINDINGS - FEATURE IMPORTANCE SUMMARY\")\n",
                "print(\"=\"*80)\n",
                "\n",
                "print(\"\\n1. SHAP ANALYSIS (SHAPLEY VALUES):\")\n",
                "print(\"-\" * 80)\n",
                "for model_name, importance_df in shap_results.items():\n",
                "    print(f\"\\n{model_name}:\")\n",
                "    print(f\"  Top 5 Features:\")\n",
                "    for idx, row in importance_df.head(5).iterrows():\n",
                "        print(f\"    â€¢ {row['Feature']:.<40} {row['Importance']:.4f}\")\n",
                "\n",
                "print(\"\\n\\n2. LIME ANALYSIS (LOCAL INTERPRETABLE MODEL-AGNOSTIC):\")\n",
                "print(\"-\" * 80)\n",
                "for model_name, importance_series in lime_results.items():\n",
                "    print(f\"\\n{model_name}:\")\n",
                "    print(f\"  Top 5 Features:\")\n",
                "    for idx, (feature, weight) in enumerate(importance_series.head(5).items()):\n",
                "        print(f\"    â€¢ {feature:.<40} {weight:.4f}\")\n",
                "\n",
                "print(\"\\n\\n3. TREND ANALYSIS:\")\n",
                "print(\"-\" * 80)\n",
                "print(f\"  Data Points: {len(df)}\")\n",
                "print(f\"  AQI Range: {df['aqi'].min():.1f} - {df['aqi'].max():.1f}\")\n",
                "print(f\"  AQI Mean: {df['aqi'].mean():.1f}\")\n",
                "print(f\"  AQI Std Dev: {df['aqi'].std():.1f}\")\n",
                "\n",
                "print(\"\\n  Top Pollutant Correlations with AQI:\")\n",
                "corr_with_aqi_sorted = df[pollutants_with_aqi].corr()['aqi'].drop('aqi').sort_values(ascending=False)\n",
                "for feature, corr in corr_with_aqi_sorted.head(5).items():\n",
                "    print(f\"    â€¢ {feature:.<40} {corr:.4f}\")\n",
                "\n",
                "print(\"\\n\" + \"=\"*80)\n",
                "print(\"Analysis Complete!\")\n",
                "print(\"=\"*80)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
